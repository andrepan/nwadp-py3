{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.01171875],\n",
      "       [ 0.0703125 ],\n",
      "       [ 0.0703125 ],\n",
      "       [ 0.0703125 ],\n",
      "       [ 0.4921875 ],\n",
      "       [ 0.53125   ],\n",
      "       [ 0.68359375],\n",
      "       [ 0.1015625 ],\n",
      "       [ 0.6484375 ],\n",
      "       [ 0.99609375],\n",
      "       [ 0.96484375],\n",
      "       [ 0.49609375],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.1171875 ],\n",
      "       [ 0.140625  ],\n",
      "       [ 0.3671875 ],\n",
      "       [ 0.6015625 ],\n",
      "       [ 0.6640625 ],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.87890625],\n",
      "       [ 0.671875  ],\n",
      "       [ 0.98828125],\n",
      "       [ 0.9453125 ],\n",
      "       [ 0.76171875],\n",
      "       [ 0.25      ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.19140625],\n",
      "       [ 0.9296875 ],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98046875],\n",
      "       [ 0.36328125],\n",
      "       [ 0.3203125 ],\n",
      "       [ 0.3203125 ],\n",
      "       [ 0.21875   ],\n",
      "       [ 0.15234375],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.0703125 ],\n",
      "       [ 0.85546875],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.7734375 ],\n",
      "       [ 0.7109375 ],\n",
      "       [ 0.96484375],\n",
      "       [ 0.94140625],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.3125    ],\n",
      "       [ 0.609375  ],\n",
      "       [ 0.41796875],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.80078125],\n",
      "       [ 0.04296875],\n",
      "       [ 0.        ],\n",
      "       [ 0.16796875],\n",
      "       [ 0.6015625 ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.0546875 ],\n",
      "       [ 0.00390625],\n",
      "       [ 0.6015625 ],\n",
      "       [ 0.98828125],\n",
      "       [ 0.3515625 ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.54296875],\n",
      "       [ 0.98828125],\n",
      "       [ 0.7421875 ],\n",
      "       [ 0.0078125 ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.04296875],\n",
      "       [ 0.7421875 ],\n",
      "       [ 0.98828125],\n",
      "       [ 0.2734375 ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.13671875],\n",
      "       [ 0.94140625],\n",
      "       [ 0.87890625],\n",
      "       [ 0.625     ],\n",
      "       [ 0.421875  ],\n",
      "       [ 0.00390625],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.31640625],\n",
      "       [ 0.9375    ],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.46484375],\n",
      "       [ 0.09765625],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.17578125],\n",
      "       [ 0.7265625 ],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.5859375 ],\n",
      "       [ 0.10546875],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.0625    ],\n",
      "       [ 0.36328125],\n",
      "       [ 0.984375  ],\n",
      "       [ 0.98828125],\n",
      "       [ 0.73046875],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.97265625],\n",
      "       [ 0.98828125],\n",
      "       [ 0.97265625],\n",
      "       [ 0.25      ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.1796875 ],\n",
      "       [ 0.5078125 ],\n",
      "       [ 0.71484375],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.80859375],\n",
      "       [ 0.0078125 ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.15234375],\n",
      "       [ 0.578125  ],\n",
      "       [ 0.89453125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.9765625 ],\n",
      "       [ 0.7109375 ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.09375   ],\n",
      "       [ 0.4453125 ],\n",
      "       [ 0.86328125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.78515625],\n",
      "       [ 0.3046875 ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.08984375],\n",
      "       [ 0.2578125 ],\n",
      "       [ 0.83203125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.7734375 ],\n",
      "       [ 0.31640625],\n",
      "       [ 0.0078125 ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.0703125 ],\n",
      "       [ 0.66796875],\n",
      "       [ 0.85546875],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.76171875],\n",
      "       [ 0.3125    ],\n",
      "       [ 0.03515625],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.21484375],\n",
      "       [ 0.671875  ],\n",
      "       [ 0.8828125 ],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.953125  ],\n",
      "       [ 0.51953125],\n",
      "       [ 0.04296875],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.53125   ],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.98828125],\n",
      "       [ 0.828125  ],\n",
      "       [ 0.52734375],\n",
      "       [ 0.515625  ],\n",
      "       [ 0.0625    ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ],\n",
      "       [ 0.        ]], dtype=float32), array([[ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.]]))\n"
     ]
    }
   ],
   "source": [
    "td, vd, tesd = mnist_loader.load_data_wrapper()\n",
    "\n",
    "print(td[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes = (784, 30, 10)\n",
    "\n",
    "\n",
    "num_layers = len(sizes)\n",
    "#y * 1\n",
    "biases = [np.random.randn(y, 1) for y in sizes[1:]]\\\n",
    "#return y * x matrix, first is 5 * 20\n",
    "weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "#导数\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feedforward(a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        for b, w in zip(biases, weights):\n",
    "            \n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "            \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#x = np.ones((10, 1))\n",
    "x = td[0][0]\n",
    "b = feedforward(x)\n",
    "#print(b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def cost_derivative(output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def backprop(x, y):\n",
    "        global biases, weights\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros_like(b) for b in biases]\n",
    "        nabla_w = [np.zeros_like(w) for w in weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        \n",
    "        #store the z and weighted z(it is a)\n",
    "        for b, w in zip(biases, weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "            \n",
    "        # backward pass\n",
    "        delta = cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def update_mini_batch(mini_batch, eta):\n",
    "        global biases, weights\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        weights = [w-(eta/len(mini_batch))*nw for w, nw in zip(weights, nabla_w)]\n",
    "        biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(biases, nabla_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def evaluate(test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(feedforward(x)), y) for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate1(test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(feedforward(x)), np.argmax(y)) for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def SGD(training_data, epochs, mini_batch_size, eta, test_data=None):\n",
    "        global biases, weights\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        print(\"Test data size if {0}\".format(n))\n",
    "        for j in range(epochs):\n",
    "            #this ???not effective\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k : k +  mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print(\"Epoch {0}: Study Acc:{1:2f}, Test Acc: {2} / {3}\".format(j, evaluate1(training_data)/n, evaluate(test_data), n_test))\n",
    "            else:\n",
    "                print(\"Epoch {0} complete\".format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size if 1000\n",
      "Epoch 0: Study Acc:0.991000, Test Acc: 9485 / 10000\n",
      "Epoch 1: Study Acc:0.991000, Test Acc: 9485 / 10000\n",
      "Epoch 2: Study Acc:0.991000, Test Acc: 9486 / 10000\n",
      "Epoch 3: Study Acc:0.991000, Test Acc: 9484 / 10000\n",
      "Epoch 4: Study Acc:0.991000, Test Acc: 9480 / 10000\n",
      "Epoch 5: Study Acc:0.991000, Test Acc: 9482 / 10000\n",
      "Epoch 6: Study Acc:0.991000, Test Acc: 9484 / 10000\n",
      "Epoch 7: Study Acc:0.991000, Test Acc: 9485 / 10000\n",
      "Epoch 8: Study Acc:0.991000, Test Acc: 9485 / 10000\n",
      "Epoch 9: Study Acc:0.991000, Test Acc: 9484 / 10000\n",
      "Epoch 10: Study Acc:0.991000, Test Acc: 9485 / 10000\n",
      "Epoch 11: Study Acc:0.991000, Test Acc: 9486 / 10000\n",
      "Epoch 12: Study Acc:0.991000, Test Acc: 9486 / 10000\n",
      "Epoch 13: Study Acc:0.991000, Test Acc: 9485 / 10000\n",
      "Epoch 14: Study Acc:0.992000, Test Acc: 9483 / 10000\n",
      "Epoch 15: Study Acc:0.991000, Test Acc: 9483 / 10000\n",
      "Epoch 16: Study Acc:0.992000, Test Acc: 9483 / 10000\n",
      "Epoch 17: Study Acc:0.991000, Test Acc: 9480 / 10000\n",
      "Epoch 18: Study Acc:0.992000, Test Acc: 9479 / 10000\n",
      "Epoch 19: Study Acc:0.991000, Test Acc: 9479 / 10000\n",
      "Epoch 20: Study Acc:0.992000, Test Acc: 9477 / 10000\n",
      "Epoch 21: Study Acc:0.992000, Test Acc: 9480 / 10000\n",
      "Epoch 22: Study Acc:0.991000, Test Acc: 9474 / 10000\n",
      "Epoch 23: Study Acc:0.992000, Test Acc: 9473 / 10000\n",
      "Epoch 24: Study Acc:0.992000, Test Acc: 9473 / 10000\n",
      "Epoch 25: Study Acc:0.992000, Test Acc: 9470 / 10000\n",
      "Epoch 26: Study Acc:0.992000, Test Acc: 9469 / 10000\n",
      "Epoch 27: Study Acc:0.992000, Test Acc: 9470 / 10000\n",
      "Epoch 28: Study Acc:0.992000, Test Acc: 9468 / 10000\n",
      "Epoch 29: Study Acc:0.992000, Test Acc: 9469 / 10000\n"
     ]
    }
   ],
   "source": [
    "SGD(td[0:1000], 30, 10, 3.0, test_data=tesd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
